# coding: utf-8
"""
テンソルを補完するための函数を呼ぶ前のインターフェイスとか前処理
"""

from numpy import *
from numpy.linalg import *

import algorithm as alg
import newalg

from logger import *
import const

#log = Logger("Completion")
print "KKKKKKKKK"

def InitializeDiagAndSimilarity(Y,Ls):
    """
    書いた覚えがない…
    内容的にはseparateLaplacianと同一
    """
    for n,size in enumerate(Y.shape):
        if Ls[n] == None:
            Ls[n] = eye(size,size)

    Ds = [diag(L) for L in Ls]
    Ws = [-(Ls[i] - Ds[i]) for i in xrange(len(Ls))]

    return Ws,Ds

def DecomposeLaplacians(Ls):
    """
    グラフラプラシアンを固有値分解する。
    """
    Ds=[]
    Ps=[]
    for n in xrange(len(Ls)):
        if Ls[n]==None:
            Ps.append(None)
            Ds.append(None)
        else:
            (v,P) = eigh(Ls[n])
            Ps.append(P)
            Ds.append(v)
    return (Ps,Ds)
def CompletionCP(Y,observed,rank_estimate,Ls,alpha,beta):
    """
    CP分解による補完
    """
    assert(isinstance(Ls,list))
    assert(not isinstance(rank_estimate,list))

    if Ls == None:
        Ls = [None for i in xrange(N)]
    (Ps,Ds) = DecomposeLaplacians(Ls)
    #print "Singular Decomposed L"
        
    I = alg.createUnitTensor(Y.ndim,rank_estimate)
    def approximate(Xin):
        As = alg.RRMFCP(Xin,rank_estimate,beta,Ls,alpha,Ps,Ds)
        Xs = alg.expand(I,As)
        return Xs

    return Completion(Y,observed,approximate)

def CompletionTucker(Y,Observed,rank_estimate,L,alpha):
    """
    Tucker分解による補完
    """
    assert(isinstance(L,list))
    assert(isinstance(rank_estimate,list))

    #print L

    def approximate(Xin):
        (G,As) = alg.HOOI(Xin,rank_estimate,alpha,L)
        Xs = alg.expand(G,As)
        return Xs
    return Completion(Y,Observed,approximate)



#Cp分解による補完
def CompletionCP_EveryStep(Y,Observed,rank_estimate,Ls,alpha,beta):
    """
    EM-ALS CP分解
    """
    assert(isinstance(Ls,list))
    assert(not isinstance(rank_estimate,list))
    N = Y.ndim
    R = rank_estimate
#X,As->Xnew
    if Ls == None:
        Ls = [None for i in xrange(N)]

    Ps,Ds = DecomposeLaplacians(Ls)

    I = alg.createUnitTensor(N,R)

    updater = lambda X,G,As:(I,alg.RRMFCPstep(As=As,X=X,R=rank_estimate,beta=beta,Ls=Ls,Ps=Ps,Ds=Ds,alpha=alpha))
    return newalg.CompletionStep(Y,Observed,Y,updater)


#Cp分解による補完
def CompletionCPProd_EveryStep(Y,Observed,rank_estimate,Ls,alpha,beta):
    """
    EM-ALS CP分解/Kronecker積バージョン
    """
    assert(isinstance(Ls,list))
    assert(not isinstance(rank_estimate,list))
    N = Y.ndim
    R = rank_estimate
#X,As->Xnew
    if Ls == None:
        Ls = [None for i in xrange(N)]

    I = alg.createUnitTensor(N,R)

    updater = lambda X,G,As:(I,alg.RRMFCPProdstep(As=As,X=X,R=rank_estimate,beta=beta,Ls=Ls,alpha=alpha))
    return newalg.CompletionStep(Y,Observed,Y,updater)

#Tucker分解による補完 高速版
def CompletionTucker_EveryStep(Y,Observed,rank_estimate,L,alpha):
    """
    EM-ALS Tucker分解
    """
    assert(isinstance(L,list))
    assert(isinstance(rank_estimate,list))

#X,As->G,AS
    updater = lambda X,G,As:alg.HOOIstep(G,As,X,Rs=rank_estimate,alpha=alpha,Ls=L)
    return newalg.CompletionStep(Y,Observed,Y,updater)

#Tucker分解による補完 高速版
def CompletionTuckerProd_EveryStep(Y,Observed,rank_estimate,L,alpha):
    """
    EM-ALS Tucker分解/Kronecker積バージョン
    """
    assert(isinstance(L,list))
    assert(isinstance(rank_estimate,list))

#X,As->G,AS
    updater = lambda X,G,As:alg.HOOIProdstep(G,As,X,Rs=rank_estimate,alpha=alpha,Ls=L)
    return newalg.CompletionStep(Y,Observed,Y,updater)

def CompletionKS_CP_EveryStep(Y,Observed,rank_estimate,Ls,alpha):
    """
    EM-ALS CP分解/全体に対する正則化
    """
    N = Y.ndim
    R = rank_estimate
#X,As->Xnew
    if Ls == None:
        Ls = [None for i in xrange(N)]
    Ps,Ds = DecomposeLaplacians(Ls)

    I = alg.createUnitTensor(N,R)

    updater = lambda X,G,As:(I,alg.CPKsumStep(As=As,X=X,R=rank_estimate,Ls=Ls,Ps=Ps,Ds=Ds,alpha=alpha))
    return newalg.CompletionStep(Y,Observed,Y,updater)


def CompletionKS_Tucker_EveryStep(Y,Observed,rank_estimate,L,alpha):
    """
    EM-ALS Tucker分解/全体に対する正則化
    """
    assert(isinstance(L,list))
    assert(isinstance(rank_estimate,list))

    Ps,Ds = DecomposeLaplacians(L)
#X,As->G,AS
    updater = lambda X,G,As:alg.TuckerKsumStep(G,As,X,Rs=rank_estimate,Ls=L,Ps=Ps,Ds=Ds,alpha=alpha)
    return newalg.CompletionStep(Y,Observed,Y,updater)



def CompletionKP_CP_EveryStep(Y,Observed,rank_estimate,Ls,alpha):
    """
    EM-ALS CP分解/全体に対する正則化/Kronecker積バージョン
    """
    assert(isinstance(Ls,list))

    N = Y.ndim
    R = rank_estimate
    Ws,Ds = InitializeDiagAndSimilarity(Y,Ls)
    PWs,DWs = DecomposeLaplacians(Ws)
    I = alg.createUnitTensor(N,R)

    updater = lambda X,G,As:(I,alg.CPKprodStep(As=As,X=X,R=rank_estimate,Ds=Ds,Ws=Ws,PWs=PWs,DWs=DWs,alpha=alpha))
    return newalg.CompletionStep(Y,Observed,Y,updater)

def CompletionKP_Tucker_EveryStep(Y,Observed,rank_estimate,Ls,alpha):
    """
    EM-ALS Tucker分解/全体に対する正則化/Kronecker積バージョン
    """
    assert(isinstance(Ls,list))
    assert(isinstance(rank_estimate,list))

    Ws,Ds = InitializeDiagAndSimilarity(Y,Ls)
    PWs,DWs = DecomposeLaplacians(Ws)

#X,As->G,AS
    updater = lambda X,G,As:alg.TuckerKprodStep(G,As,X,Rs=rank_estimate,Ds=Ds,Ws=Ws,PWs=PWs,DWs=DWs,alpha=alpha)
    return newalg.CompletionStep(Y,Observed,Y,updater)


def CompletionDistance_CP_Everystep(Y,Observed,rank_estimate,Ls,alpha):
    """
    EM-ALS CP分解/損失関数にラプラシアン
    """
    N = Y.ndim
    R = rank_estimate
    I = alg.createUnitTensor(N,R)
    updater = lambda X,G,As:(I,alg.CPDistanceStep(As,X,R=rank_estimate,Ls=Ls,alpha=alpha))
    return newalg.CompletionStep(Y,Observed,Y,updater)

def CompletionDistance_Tucker_EveryStep(Y,Observed,rank_estimate,Ls,alpha):
    """
    EM-ALS Tucker分解/損失関数にラプラシアン
    """
    updater = lambda X,G,As:alg.TuckerDistanceStep(G,As,X,Rs=rank_estimate,Ls=Ls,alpha=alpha)
    return newalg.CompletionStep(Y,Observed,Y,updater)

